{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier \n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train['target']\n",
    "del train['target']\n",
    "\n",
    "test_id = test['ID_code']\n",
    "\n",
    "train.drop('ID_code',axis=1 , inplace=True)\n",
    "test.drop('ID_code',axis=1 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(x,y,t=2):\n",
    "    xs,xn = [],[]\n",
    "    #두번반복한다는이야기\n",
    "    for i in range(t):\n",
    "        #y==1 일경우\n",
    "        mask = y>0\n",
    "        x1 = x[mask].copy()\n",
    "        #x1의 인덱스 추출\n",
    "        ids = np.arange(x1.shape[0])\n",
    "        #x1의 컬럼 수만큼 for roop 하면서 인덱스를 섞어주고 섞어줄떄마다 컬럼 하나씩 붙인다.\n",
    "        # 전체로우에 인덱스를 계속 바꾸면서 컬럼을 1,2,3.... 하나씩 넣어준다\n",
    "        for c in range(x1.shape[1]):\n",
    "            np.random.shuffle(ids)\n",
    "            x1[:,c] = x1[ids][:,c]\n",
    "        xs.append(x1)\n",
    "    #한번 반복한다는 이야기\n",
    "    for i in range(t//2):\n",
    "        mask = y==0\n",
    "        x1 = x[mask].copy()\n",
    "        ids = np.arange(x1.shape[0])\n",
    "        for c in range(x1.shape[1]):\n",
    "            np.random.shuffle(ids)\n",
    "            x1[:,c] = x1[ids][:,c]\n",
    "        xn.append(x1)\n",
    "    #Must pass 2-d input  2d가 아니기 떄문에 vstack로 쌓아준다\n",
    "    xs = np.vstack(xs)\n",
    "    xn = np.vstack(xn)\n",
    "    ys = np.ones(xs.shape[0])\n",
    "    yn = np.zeros(xn.shape[0])\n",
    "    x = np.vstack([x,xs,xn])\n",
    "    y = np.concatenate([y,ys,yn])\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'bagging_freq': 5,\n",
    "    'bagging_fraction': 0.335,\n",
    "    'boost_from_average':'false',\n",
    "    'boost': 'gbdt',\n",
    "    'feature_fraction': 0.041,\n",
    "    'learning_rate': 0.0083,\n",
    "    'max_depth': -1,\n",
    "    'metric':'auc',\n",
    "    'min_data_in_leaf': 80,\n",
    "    'min_sum_hessian_in_leaf': 10.0,\n",
    "    'num_leaves': 13,\n",
    "    'num_threads': 8,\n",
    "    'tree_learner': 'serial',\n",
    "    'objective': 'binary', \n",
    "    'verbosity': -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Light GBM Model\n",
      "Fold idx:1\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[1000]\ttraining's auc: 0.893906\tvalid_1's auc: 0.882102\n",
      "[2000]\ttraining's auc: 0.901813\tvalid_1's auc: 0.888329\n",
      "[3000]\ttraining's auc: 0.906758\tvalid_1's auc: 0.89189\n",
      "[4000]\ttraining's auc: 0.910549\tvalid_1's auc: 0.8946\n",
      "[5000]\ttraining's auc: 0.91355\tvalid_1's auc: 0.896134\n",
      "[6000]\ttraining's auc: 0.916105\tvalid_1's auc: 0.89745\n",
      "[7000]\ttraining's auc: 0.918359\tvalid_1's auc: 0.898284\n",
      "[8000]\ttraining's auc: 0.920438\tvalid_1's auc: 0.898861\n",
      "[9000]\ttraining's auc: 0.922409\tvalid_1's auc: 0.899236\n",
      "[10000]\ttraining's auc: 0.924238\tvalid_1's auc: 0.899465\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's auc: 0.924238\tvalid_1's auc: 0.899465\n",
      "Fold idx:2\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[1000]\ttraining's auc: 0.894562\tvalid_1's auc: 0.878551\n",
      "[2000]\ttraining's auc: 0.902585\tvalid_1's auc: 0.885767\n",
      "[3000]\ttraining's auc: 0.90775\tvalid_1's auc: 0.889882\n",
      "[4000]\ttraining's auc: 0.911564\tvalid_1's auc: 0.892592\n",
      "[5000]\ttraining's auc: 0.914552\tvalid_1's auc: 0.894174\n",
      "[6000]\ttraining's auc: 0.917049\tvalid_1's auc: 0.895436\n",
      "[7000]\ttraining's auc: 0.919351\tvalid_1's auc: 0.896254\n",
      "[8000]\ttraining's auc: 0.92141\tvalid_1's auc: 0.896762\n",
      "[9000]\ttraining's auc: 0.923323\tvalid_1's auc: 0.897082\n",
      "[10000]\ttraining's auc: 0.925124\tvalid_1's auc: 0.897313\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's auc: 0.925124\tvalid_1's auc: 0.897313\n",
      "Fold idx:3\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[1000]\ttraining's auc: 0.893154\tvalid_1's auc: 0.885102\n",
      "[2000]\ttraining's auc: 0.901301\tvalid_1's auc: 0.891931\n",
      "[3000]\ttraining's auc: 0.906459\tvalid_1's auc: 0.895523\n",
      "[4000]\ttraining's auc: 0.910308\tvalid_1's auc: 0.898005\n",
      "[5000]\ttraining's auc: 0.913345\tvalid_1's auc: 0.899643\n",
      "[6000]\ttraining's auc: 0.915893\tvalid_1's auc: 0.900609\n",
      "[7000]\ttraining's auc: 0.918169\tvalid_1's auc: 0.901301\n",
      "[8000]\ttraining's auc: 0.92021\tvalid_1's auc: 0.901666\n",
      "[9000]\ttraining's auc: 0.922121\tvalid_1's auc: 0.901891\n",
      "[10000]\ttraining's auc: 0.923976\tvalid_1's auc: 0.90216\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's auc: 0.923976\tvalid_1's auc: 0.90216\n",
      "Fold idx:4\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[1000]\ttraining's auc: 0.894214\tvalid_1's auc: 0.883461\n",
      "[2000]\ttraining's auc: 0.902129\tvalid_1's auc: 0.890033\n",
      "[3000]\ttraining's auc: 0.907174\tvalid_1's auc: 0.893846\n",
      "[4000]\ttraining's auc: 0.91097\tvalid_1's auc: 0.896579\n",
      "[5000]\ttraining's auc: 0.913959\tvalid_1's auc: 0.898299\n",
      "[6000]\ttraining's auc: 0.916509\tvalid_1's auc: 0.899496\n",
      "[7000]\ttraining's auc: 0.918748\tvalid_1's auc: 0.900326\n",
      "[8000]\ttraining's auc: 0.920776\tvalid_1's auc: 0.900728\n",
      "[9000]\ttraining's auc: 0.922643\tvalid_1's auc: 0.901014\n",
      "[10000]\ttraining's auc: 0.924464\tvalid_1's auc: 0.90129\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's auc: 0.924464\tvalid_1's auc: 0.90129\n",
      "Fold idx:5\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[1000]\ttraining's auc: 0.89331\tvalid_1's auc: 0.88773\n",
      "[2000]\ttraining's auc: 0.901329\tvalid_1's auc: 0.893593\n",
      "[3000]\ttraining's auc: 0.906402\tvalid_1's auc: 0.897479\n",
      "[4000]\ttraining's auc: 0.910318\tvalid_1's auc: 0.899846\n",
      "[5000]\ttraining's auc: 0.913306\tvalid_1's auc: 0.901319\n",
      "[6000]\ttraining's auc: 0.915907\tvalid_1's auc: 0.9024\n",
      "[7000]\ttraining's auc: 0.91822\tvalid_1's auc: 0.903073\n",
      "[8000]\ttraining's auc: 0.92031\tvalid_1's auc: 0.903483\n",
      "[9000]\ttraining's auc: 0.922222\tvalid_1's auc: 0.903767\n",
      "[10000]\ttraining's auc: 0.924042\tvalid_1's auc: 0.903889\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's auc: 0.924042\tvalid_1's auc: 0.903889\n",
      "CV score: 0.90078 \n"
     ]
    }
   ],
   "source": [
    "# frolds 지정\n",
    "num_folds = 5\n",
    "#.columns를 통해 변수 지정\n",
    "features = [c for c in train.columns ]\n",
    "\n",
    "#계층별 kfold\n",
    "folds = StratifiedKFold(n_splits=num_folds, shuffle=False, random_state=2319)\n",
    "\n",
    "oof = np.zeros(len(train))\n",
    "getVal = np.zeros(len(train))\n",
    "predictions = np.zeros(len(target))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "print('Light GBM Model')\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "    \n",
    "    X_train, y_train = train.iloc[trn_idx][features], target.iloc[trn_idx]\n",
    "    X_valid, y_valid = train.iloc[val_idx][features], target.iloc[val_idx]\n",
    "    \n",
    "    N = 3\n",
    "    p_valid,yp = 0,0\n",
    "    for i in range(N):\n",
    "        X_tr, y_tr = augment(X_train.values, y_train.values)\n",
    "        X_tr = pd.DataFrame(X_tr)\n",
    "    \n",
    "        trn_data = lgb.Dataset(X_tr, label=y_tr)\n",
    "        val_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "    \n",
    "        clf = lgb.train(param, trn_data, 10000 ,valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 4000)\n",
    "        oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "        getVal[val_idx]+= clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions += clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##submission\n",
    "sub_df1 = pd.DataFrame({\"ID_code\":test_id})\n",
    "sub_df1[\"target\"] = predictions\n",
    "sub_df1.to_csv(\"lgboost_oof_augment.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
